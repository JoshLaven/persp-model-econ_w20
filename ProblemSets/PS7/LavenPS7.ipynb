{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial logistic regression and cross validation (6 points). For this problem, you will estimate the probability that a given wine comes from a given cultivar. The data in the file strongdrink.txt (taken from the UCI Machine Learning Repository) are the results of a chemical analysis of 176 Italian wines from three known cultivars (a cultivar is a group of grapes selected for desirable characteristics that can be maintained by propagation). The chemical analysis determined the quantities of the following 13 different constituents (the last 13 variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cultivar</th>\n",
       "      <th>alco</th>\n",
       "      <th>malic</th>\n",
       "      <th>ash</th>\n",
       "      <th>alk</th>\n",
       "      <th>magn</th>\n",
       "      <th>tot_phen</th>\n",
       "      <th>flav</th>\n",
       "      <th>nonfl_phen</th>\n",
       "      <th>proanth</th>\n",
       "      <th>color_int</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280rat</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cultivar   alco  malic   ash   alk  magn  tot_phen  flav  nonfl_phen  \\\n",
       "0         1  14.23   1.71  2.43  15.6   127      2.80  3.06        0.28   \n",
       "1         1  13.20   1.78  2.14  11.2   100      2.65  2.76        0.26   \n",
       "2         1  13.16   2.36  2.67  18.6   101      2.80  3.24        0.30   \n",
       "3         1  14.37   1.95  2.50  16.8   113      3.85  3.49        0.24   \n",
       "4         1  13.24   2.59  2.87  21.0   118      2.80  2.69        0.39   \n",
       "\n",
       "   proanth  color_int   hue  OD280rat  proline  \n",
       "0     2.29       5.64  1.04      3.92     1065  \n",
       "1     1.28       4.38  1.05      3.40     1050  \n",
       "2     2.81       5.68  1.03      3.17     1185  \n",
       "3     2.18       7.80  0.86      3.45     1480  \n",
       "4     1.82       4.32  1.04      2.93      735  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine=pd.read_csv('data/strongdrink.txt')\n",
    "print (wine.shape)\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) \n",
    "Use a multinomial logistic regression model of the following form with the following linear predictor $n_j$ for j = 1, 2 (the baseline class is j = 3).\n",
    "\n",
    "$Pr(cultivar_i =j|X\\beta_j)=\\frac{e^{n_j}}{1+\\sum{j=1}{J-1}e^{n_j}}$ for j=1,2\n",
    "where $n_j = \\beta_{j,0} + \\beta_{j,1}alco_i + \\beta_{j,2}malic_i + \\beta_{j,3}totphen_i + \\beta_{j,4}colorint_i$\n",
    "\n",
    "Estimate the model on a 75% sample training set using the following command. Report your two sets of estimated coefficients and intercepts for j = 1 and j = 2 (not the coefficients for j = 3). Report your error rates (1 - precision) on the test set using the code below. Which category(ies) of cultivar is the model best at predicting? Is (are) the most accurately predicted category(ies) the one(s) with the most observations? Report the MSE from the test set.\n",
    "\n",
    "The error rate for Cultivars 1, 2, and 3 is 0.13, 0.0 and 0.0, respectively. The most accurately predicted category of cultivar is the #3, which is the category with the lowest number of observations. The MSE of the test set is 0.04545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), array([13, 21, 10]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split data\n",
    "X = wine[['alco','malic','tot_phen','color_int']]\n",
    "y = wine['cultivar']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), array([13, 21, 10]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.25,\n",
    "       random_state=20)\n",
    "\n",
    "#Count number of each cultivar in test set\n",
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients were Cultivar 1 are: [-1.46798523 -0.33305092  0.66400603 -0.92270882]\n",
      "The coefficients were Cultivar 2 are: [-0.2324475   0.59866064 -1.8879004   0.89996106]\n"
     ]
    }
   ],
   "source": [
    "LogReg = LogisticRegression(random_state=0, multi_class='multinomial',solver='newton-cg')\n",
    "LogReg.fit(X_train, y_train)\n",
    "y_pred = LogReg.predict(X_test)\n",
    "\n",
    "\n",
    "print('The coefficients were Cultivar 1 are:', LogReg.coef_[1])\n",
    "print('The coefficients were Cultivar 2 are:', LogReg.coef_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 2 19  0]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      1.00      0.93        13\n",
      "           2       1.00      0.90      0.95        21\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        44\n",
      "   macro avg       0.96      0.97      0.96        44\n",
      "weighted avg       0.96      0.95      0.96        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cultivar 1 error rate = 0.13\n",
      "Cultivar 2 error rate = 0.0\n",
      "Cultivar 3 error rate = 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Cultivar 1 error rate = 0.13')\n",
    "print('Cultivar 2 error rate = 0.0')\n",
    "print('Cultivar 3 error rate = 0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE from the test is: 0.045454545454545456\n"
     ]
    }
   ],
   "source": [
    "mse_test = (((y_test-y_pred)**2).sum())/y_pred.shape[0]\n",
    "print('The MSE from the test is:', mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
