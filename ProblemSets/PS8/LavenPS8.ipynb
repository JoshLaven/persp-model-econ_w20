{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Josh Laven\n",
    "\n",
    "# Problem Set 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Decision trees (5 points).\n",
    "Joe Biden was the 47th Vice President of the United States. He was the subject of many memes, attracted the attention of Leslie Knope (Parks and Recreation, TV sitcom), and experienced a brief surge in attention due to photos from his youth. The data file biden.csv contains a selection of variables from the 2008 American National Election Studies survey that allow you to test competing factors that may influence attitudes towards Joe Biden. The variables are coded as follows:\n",
    "\n",
    "-biden: feeling thermometer ranging from 0 to 100. Feeling thermometers are a common metric in survey research used to gauge attitudes or feelings of warmth towards individuals and institutions. They range from 0-100, with 0 indicating extreme coldness and 100 indicating extreme warmth.<br>\n",
    "\n",
    "-female: =1 if respondent is female, =0 if respondent is male <br>\n",
    "\n",
    "-age: age of respondent in years, range from 18 to 93 <br>\n",
    "\n",
    "-dem: =1 if respondent is a Democrat, =0 otherwise<br>\n",
    "\n",
    "-rep: =1 if respondent is a Republican, =0 otherwise<br>\n",
    "\n",
    "-educ: number of years of formal education completed by respondent, range from 0 to 17 with 17+ representing the first year of grad school and up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) \n",
    "Split the data into a training set (70%) and a test set (30%) using the sklearn.model selection.train test split() function with random state=25. Setting the seed will guarantee you all get the same results. Use recursive\n",
    "binary splitting to fit a decision tree to the training data, with biden\n",
    "as the response variable and the other variables as predictors. Set the\n",
    "max depth=3 and min samples leaf=5. Plot the tree and interpret the results. What is the test MSE?\n",
    "\n",
    "#### Answer\n",
    "Unsurprisingly, whether a person is a Democrat is the first split in the tree. If the person is not a Democrat, the decision node then splits by whether someone is a Republican. This means that there are independents or other non-affiliated voters who, as a group, have a different opinion of Biden than Republicans. Another interesting thing is that whether someone is a female is used at three of the four decision nodes that determine the terminal nodes. The tree predicts that Democrats above 54.5 years old who are female have the highest warmth for Biden, at a predicted value of 80.289. And the model predicts that people who are neither Democrats nor Republicans and male will have the lowest warmth for Biden, at a predicted value of 56.489.\n",
    "\n",
    "The test MSE for this decision tree is 396.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_data = pd.read_csv('Biden.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biden</th>\n",
       "      <th>female</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>dem</th>\n",
       "      <th>rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   biden  female  age  educ  dem  rep\n",
       "0     90       0   19    12    1    0\n",
       "1     70       1   51    14    1    0\n",
       "2     60       0   27    14    0    0\n",
       "3     50       1   43    14    1    0\n",
       "4     60       1   38    14    0    1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= biden_data[['female','age','educ','dem','rep']]\n",
    "y= biden_data[['biden']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=5,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_tree = DecisionTreeRegressor(max_depth=3, min_samples_leaf=5)\n",
    "biden_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"1014pt\" height=\"373pt\"\n",
       " viewBox=\"0.00 0.00 1014.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 1010,-369 1010,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.568627\" stroke=\"#000000\" d=\"M549,-365C549,-365 457,-365 457,-365 451,-365 445,-359 445,-353 445,-353 445,-309 445,-309 445,-303 451,-297 457,-297 457,-297 549,-297 549,-297 555,-297 561,-303 561,-309 561,-309 561,-353 561,-353 561,-359 555,-365 549,-365\"/>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 556.262</text>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1264</text>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 62.165</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.345098\" stroke=\"#000000\" d=\"M418,-261C418,-261 332,-261 332,-261 326,-261 320,-255 320,-249 320,-249 320,-205 320,-205 320,-199 326,-193 332,-193 332,-193 418,-193 418,-193 424,-193 430,-199 430,-205 430,-205 430,-249 430,-249 430,-255 424,-261 418,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[4] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 507.397</text>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 724</text>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 52.811</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M461.088,-296.9465C449.485,-287.519 436.7779,-277.1946 424.7741,-267.4415\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"426.9744,-264.7196 417.0061,-261.13 422.5602,-270.1524 426.9744,-264.7196\"/>\n",
       "<text text-anchor=\"middle\" x=\"419.5786\" y=\"-282.2973\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.866667\" stroke=\"#000000\" d=\"M674,-261C674,-261 588,-261 588,-261 582,-261 576,-255 576,-249 576,-249 576,-205 576,-205 576,-199 582,-193 588,-193 588,-193 674,-193 674,-193 680,-193 686,-199 686,-205 686,-205 686,-249 686,-249 686,-255 680,-261 674,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"631\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[1] &lt;= 54.5</text>\n",
       "<text text-anchor=\"middle\" x=\"631\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 347.197</text>\n",
       "<text text-anchor=\"middle\" x=\"631\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 540</text>\n",
       "<text text-anchor=\"middle\" x=\"631\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 74.706</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M544.912,-296.9465C556.515,-287.519 569.2221,-277.1946 581.2259,-267.4415\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"583.4398,-270.1524 588.9939,-261.13 579.0256,-264.7196 583.4398,-270.1524\"/>\n",
       "<text text-anchor=\"middle\" x=\"586.4214\" y=\"-282.2973\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.490196\" stroke=\"#000000\" d=\"M226,-157C226,-157 140,-157 140,-157 134,-157 128,-151 128,-145 128,-145 128,-101 128,-101 128,-95 134,-89 140,-89 140,-89 226,-89 226,-89 232,-89 238,-95 238,-101 238,-101 238,-145 238,-145 238,-151 232,-157 226,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 444.551</text>\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 468</text>\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 58.868</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M319.9805,-197.1978C297.1844,-184.8499 270.5931,-170.4463 246.9364,-157.6322\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"248.4875,-154.4919 238.0275,-152.8066 245.1535,-160.647 248.4875,-154.4919\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.082353\" stroke=\"#000000\" d=\"M418,-157C418,-157 332,-157 332,-157 326,-157 320,-151 320,-145 320,-145 320,-101 320,-101 320,-95 326,-89 332,-89 332,-89 418,-89 418,-89 424,-89 430,-95 430,-101 430,-101 430,-145 430,-145 430,-151 424,-157 418,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 432.623</text>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 256</text>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 41.738</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M375,-192.9465C375,-184.776 375,-175.9318 375,-167.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"378.5001,-167.13 375,-157.13 371.5001,-167.13 378.5001,-167.13\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.431373\" stroke=\"#000000\" d=\"M98,-53C98,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 98,0 98,0 104,0 110,-6 110,-12 110,-12 110,-41 110,-41 110,-47 104,-53 98,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"55\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 470.335</text>\n",
       "<text text-anchor=\"middle\" x=\"55\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 235</text>\n",
       "<text text-anchor=\"middle\" x=\"55\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 56.489</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M137.872,-88.9777C125.1187,-79.3629 111.2673,-68.9203 98.6053,-59.3743\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.5719,-56.4737 90.4798,-53.2485 96.3579,-62.0632 100.5719,-56.4737\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.545098\" stroke=\"#000000\" d=\"M226,-53C226,-53 140,-53 140,-53 134,-53 128,-47 128,-41 128,-41 128,-12 128,-12 128,-6 134,0 140,0 140,0 226,0 226,0 232,0 238,-6 238,-12 238,-12 238,-41 238,-41 238,-47 232,-53 226,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 407.088</text>\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 233</text>\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 61.266</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M183,-88.9777C183,-80.7364 183,-71.887 183,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.5001,-63.2484 183,-53.2485 179.5001,-63.2485 186.5001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"transparent\" stroke=\"#000000\" d=\"M354,-53C354,-53 268,-53 268,-53 262,-53 256,-47 256,-41 256,-41 256,-12 256,-12 256,-6 262,0 268,0 268,0 354,0 354,0 360,0 366,-6 366,-12 366,-12 366,-41 366,-41 366,-47 360,-53 354,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 456.775</text>\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 123</text>\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 38.333</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M352.436,-88.9777C346.6059,-80.187 340.3169,-70.7044 334.443,-61.8477\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"337.1838,-59.6478 328.7399,-53.2485 331.3502,-63.5167 337.1838,-59.6478\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.156863\" stroke=\"#000000\" d=\"M482,-53C482,-53 396,-53 396,-53 390,-53 384,-47 384,-41 384,-41 384,-12 384,-12 384,-6 390,0 396,0 396,0 482,0 482,0 488,0 494,-6 494,-12 494,-12 494,-41 494,-41 494,-47 488,-53 482,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 389.649</text>\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 133</text>\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 44.887</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M397.564,-88.9777C403.3941,-80.187 409.6831,-70.7044 415.557,-61.8477\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"418.6498,-63.5167 421.2601,-53.2485 412.8162,-59.6478 418.6498,-63.5167\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.815686\" stroke=\"#000000\" d=\"M674,-157C674,-157 588,-157 588,-157 582,-157 576,-151 576,-145 576,-145 576,-101 576,-101 576,-95 582,-89 588,-89 588,-89 674,-89 674,-89 680,-89 686,-95 686,-101 686,-101 686,-145 686,-145 686,-151 680,-157 674,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"631\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[2] &lt;= 15.5</text>\n",
       "<text text-anchor=\"middle\" x=\"631\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 345.027</text>\n",
       "<text text-anchor=\"middle\" x=\"631\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 340</text>\n",
       "<text text-anchor=\"middle\" x=\"631\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 72.606</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M631,-192.9465C631,-184.776 631,-175.9318 631,-167.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"634.5001,-167.13 631,-157.13 627.5001,-167.13 634.5001,-167.13\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.952941\" stroke=\"#000000\" d=\"M866,-157C866,-157 780,-157 780,-157 774,-157 768,-151 768,-145 768,-145 768,-101 768,-101 768,-95 774,-89 780,-89 780,-89 866,-89 866,-89 872,-89 878,-95 878,-101 878,-101 878,-145 878,-145 878,-151 872,-157 866,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 330.649</text>\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 200</text>\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 78.275</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M686.0195,-197.1978C708.8156,-184.8499 735.4069,-170.4463 759.0636,-157.6322\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"760.8465,-160.647 767.9725,-152.8066 757.5125,-154.4919 760.8465,-160.647\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.780392\" stroke=\"#000000\" d=\"M610,-53C610,-53 524,-53 524,-53 518,-53 512,-47 512,-41 512,-41 512,-12 512,-12 512,-6 518,0 524,0 524,0 610,0 610,0 616,0 622,-6 622,-12 622,-12 622,-41 622,-41 622,-47 616,-53 610,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 369.301</text>\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 247</text>\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 71.105</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M608.436,-88.9777C602.6059,-80.187 596.3169,-70.7044 590.443,-61.8477\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"593.1838,-59.6478 584.7399,-53.2485 587.3502,-63.5167 593.1838,-59.6478\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.913725\" stroke=\"#000000\" d=\"M738,-53C738,-53 652,-53 652,-53 646,-53 640,-47 640,-41 640,-41 640,-12 640,-12 640,-6 646,0 652,0 652,0 738,0 738,0 744,0 750,-6 750,-12 750,-12 750,-41 750,-41 750,-47 744,-53 738,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"695\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 258.693</text>\n",
       "<text text-anchor=\"middle\" x=\"695\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 93</text>\n",
       "<text text-anchor=\"middle\" x=\"695\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 76.591</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M653.564,-88.9777C659.3941,-80.187 665.6831,-70.7044 671.557,-61.8477\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"674.6498,-63.5167 677.2601,-53.2485 668.8162,-59.6478 674.6498,-63.5167\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.878431\" stroke=\"#000000\" d=\"M866,-53C866,-53 780,-53 780,-53 774,-53 768,-47 768,-41 768,-41 768,-12 768,-12 768,-6 774,0 780,0 780,0 866,0 866,0 872,0 878,-6 878,-12 878,-12 878,-41 878,-41 878,-47 872,-53 866,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 399.015</text>\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 79</text>\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 75.19</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M823,-88.9777C823,-80.7364 823,-71.887 823,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"826.5001,-63.2484 823,-53.2485 819.5001,-63.2485 826.5001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M994,-53C994,-53 908,-53 908,-53 902,-53 896,-47 896,-41 896,-41 896,-12 896,-12 896,-6 902,0 908,0 908,0 994,0 994,0 1000,0 1006,-6 1006,-12 1006,-12 1006,-41 1006,-41 1006,-47 1000,-53 994,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"951\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 275.743</text>\n",
       "<text text-anchor=\"middle\" x=\"951\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 121</text>\n",
       "<text text-anchor=\"middle\" x=\"951\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 80.289</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M868.128,-88.9777C880.8813,-79.3629 894.7327,-68.9203 907.3947,-59.3743\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"909.6421,-62.0632 915.5202,-53.2485 905.4281,-56.4737 909.6421,-62.0632\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x10f92c7b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "biden_tree_viz = export_graphviz(\n",
    "    biden_tree,\n",
    "    out_file=None,\n",
    "    # feature_names=iris.feature_names[2:],\n",
    "    # class_names=iris.target_names,\n",
    "    rounded=True,\n",
    "    filled=True,\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(biden_tree_viz)\n",
    "graph.render('biden_tree_viz')\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 396.1937146321307\n"
     ]
    }
   ],
   "source": [
    "y_pred = biden_tree.predict(X_test)\n",
    "MSE1 = mean_squared_error(y_test, y_pred)\n",
    "print('MSE=', MSE1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) \n",
    "Use sklearn.model selection.RandomizedSearchCV to optimally tune\n",
    "the hyperparameters in the decision tree from part (a). Tune the parameters max depth, min samples split, and min samples leaf. Set\n",
    "n iter=100, n jobs=-1, cv=5 for k = 5 k-fold cross validation, random state=25, and scoring=’neg mean squared error’. This last option will allow you\n",
    "to compare the MSE of the optimized tree (it will output the negative MSE) to the MSE calculated in part (a). Set your parameter distributions over which to test random combinations to the following.\n",
    "\n",
    "Report your optimal tuning parameter values (use the .best params object of your RandomizedSearchCV().fit(X, y)) results). Report the MSE of your optimal results (use the .best score object of your RandomizedSearchCV().fit(X, y)) results.\n",
    "\n",
    "#### Answer\n",
    "The optimal tuning parameters are: a max depth of 3, a minimum samples leaf of 17, and a minimum samples split of 14 <br>\n",
    "The test MSE for this model is 392.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "param_dist1 = {'max_depth': [3, 10],\n",
    "             'min_samples_split': sp_randint(2, 20),\n",
    "             'min_samples_leaf': sp_randint(2, 20)}\n",
    "\n",
    "biden_tree2 = DecisionTreeRegressor()\n",
    "random_search1 = RandomizedSearchCV(biden_tree2, param_distributions=param_dist1,\n",
    "                                    n_iter=100, n_jobs=-1, cv=5, random_state=25,\n",
    "                                    scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandBestEstimator1= DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=17,\n",
      "           min_samples_split=14, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      "RandBestParams1= {'max_depth': 3, 'min_samples_leaf': 17, 'min_samples_split': 14}\n",
      "RandBestScore1= 401.6903602232667\n"
     ]
    }
   ],
   "source": [
    "random_search1.fit(X, y)\n",
    "print('RandBestEstimator1=', random_search1.best_estimator_)\n",
    "print('RandBestParams1=', random_search1.best_params_)\n",
    "print('RandBestScore1=', -random_search1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 392.7116895977868\n"
     ]
    }
   ],
   "source": [
    "#Use optimal parameters\n",
    "biden_treeopt = DecisionTreeRegressor(max_depth=3, min_samples_leaf=17,min_samples_split=14)\n",
    "biden_treeopt.fit(X,y)\n",
    "\n",
    "y_pred_treeopt = biden_treeopt.predict(X_test)\n",
    "MSE_treeopt = mean_squared_error(y_test, y_pred_treeopt)\n",
    "print('MSE=', MSE_treeopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "Now tune the parameters of a RandomForest regression model on these data sklearn.ensemble.RandomForestRegressor(). Use\n",
    "sklearn.model selection.RandomizedSearchCV to optimally tune the hyperparameters in the random forest regression model. Tune the parameters n estimators, max depth, min samples split, min samples leaf, and max features. Set n iter=100, n jobs=-1, cv=5 for k = 5 k-fold cross validation, random state=25, and scoring=’neg mean squared error’. Set your Random Forest parameter distributions over which to test random combinations to the following.\n",
    "Report your optimal tuning parameter values (use the .best params object of your RandomizedSearchCV().fit(X, y)) results). Report the MSE of your optimal results (use the .best score object of your RandomizedSearchCV().fit(X, y)) results.\n",
    "\n",
    "#### Answer\n",
    "The optimal tuning parameters are: a max depth of 3, a minimum samples leaf of 17, a minimum samples split of 13, an n estimator of 10, and a maximum features of 2. <br>\n",
    "The test MSE for this model is 440.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 533.5736881299662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Create first Random Forest object\n",
    "biden_rf = RandomForestRegressor(n_estimators=100, max_features=4, bootstrap=True,\n",
    "                                  n_jobs=-1, oob_score=True, random_state=25)\n",
    "\n",
    "biden_rf.fit(X,y)\n",
    "\n",
    "\n",
    "y_pred = biden_rf.oob_prediction_\n",
    "MSE_rf = mean_squared_error(y, y_pred)\n",
    "print('MSE=', MSE_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune hyperparameters\n",
    "param_dist_tune = {'n_estimators': [10,200],\n",
    "                   'max_depth': [3, 10],'min_samples_split': sp_randint(2, 20),\n",
    "                   'min_samples_leaf': sp_randint(2, 20),'max_features':sp_randint(1,5)}\n",
    "\n",
    "biden_tune = RandomizedSearchCV(biden_rf, param_distributions=param_dist_tune,\n",
    "                                    n_iter=100, n_jobs=-1, cv=5, random_state=25,\n",
    "                                    scoring='neg_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TunedBestEstimator1= RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
      "           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=17,\n",
      "           min_samples_split=13, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=-1, oob_score=True, random_state=25,\n",
      "           verbose=0, warm_start=False)\n",
      "TunedBestParams1= {'max_depth': 3, 'max_features': 2, 'min_samples_leaf': 17, 'min_samples_split': 13, 'n_estimators': 10}\n",
      "TunedBestScore1= 397.0681090117028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:732: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    }
   ],
   "source": [
    "#Get best parameters\n",
    "biden_tune.fit(X,y)\n",
    "print('TunedBestEstimator1=', biden_tune.best_estimator_)\n",
    "print('TunedBestParams1=', biden_tune.best_params_)\n",
    "print('TunedBestScore1=', -biden_tune.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 440.2238005324634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:732: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    }
   ],
   "source": [
    "#Run new Random Forest with optimal parameters\n",
    "\n",
    "biden_rf_opt = RandomForestRegressor(n_estimators=10, max_depth=3, min_samples_split=13, min_samples_leaf=17,\n",
    "                                     max_features=2, bootstrap=True,\n",
    "                                     n_jobs=-1, oob_score=True, random_state=25)\n",
    "\n",
    "biden_rf_opt.fit(X,y)\n",
    "\n",
    "\n",
    "y_pred_rfopt = biden_rf_opt.oob_prediction_\n",
    "MSE_rfopt = mean_squared_error(y, y_pred_rfopt)\n",
    "print('MSE=', MSE_rfopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Classifier “horse” race (5 points). \n",
    "For this problem, you will use the 397 observations from the Auto.csvdataset. This dataset includes 397 observations on miles per gallon (mpg), number of cylinders (cylinders), engine displacement (displacement), horsepower (horsepower), vehicle weight (weight), accelera- tion (acceleration), vehicle year (year), vehicle origin (origin), and vehicle name (name). We will study the factors that make miles per gallon high or low. Create a binary variable mpg high that equals 1 if mpg≥ median(mpg) and equals either 0 if mpg< median(mpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0        130    3504          12.0    70   \n",
       "1  15.0          8         350.0        165    3693          11.5    70   \n",
       "2  18.0          8         318.0        150    3436          11.0    70   \n",
       "3  16.0          8         304.0        150    3433          12.0    70   \n",
       "4  17.0          8         302.0        140    3449          10.5    70   \n",
       "\n",
       "   origin                       name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('Auto.csv')\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "      <th>mpg_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0        130    3504          12.0    70   \n",
       "1  15.0          8         350.0        165    3693          11.5    70   \n",
       "2  18.0          8         318.0        150    3436          11.0    70   \n",
       "3  16.0          8         304.0        150    3433          12.0    70   \n",
       "4  17.0          8         302.0        140    3449          10.5    70   \n",
       "\n",
       "   origin                       name  mpg_high  \n",
       "0       1  chevrolet chevelle malibu         0  \n",
       "1       1          buick skylark 320         0  \n",
       "2       1         plymouth satellite         0  \n",
       "3       1              amc rebel sst         0  \n",
       "4       1                ford torino         0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto['mpg_high']= np.where(auto.mpg >= np.median(auto['mpg']),1,0)\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) \n",
    "Use sklearn.linear model.LogisticRegression to fit a logistic model of mpg high on features number of cylinders (cyl), engine displacement (dspl), horsepower (hpwr), vehicle weight (wgt), acceleration (accl), vehicle year (yr), vehicle origin 1 (orgn1), and vehicle origin 2 (orgn2). Make sure to include a constant term. Fit the model using k-fold cross validation with k = 4 folds.\n",
    "\n",
    "Report the MSE of the model as the average MSE across the k = 4 test sets, and report the error rates for each category of mpg high as the average error rate for that category across the k = 4 test sets.\n",
    "\n",
    "#### Answer\n",
    "The average MSE across the 4 tests is 0.0994. The average error rate for mpg_high = 1 is 0.0779, and the average error rate for mpg_high = 0 is 0.1193."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert non-numbers to Nans\n",
    "auto['horsepower']= pd.to_numeric(auto['horsepower'],errors = 'coerce')\n",
    "#Drop NaNs\n",
    "auto = auto.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>mpg_high</th>\n",
       "      <th>origin_1</th>\n",
       "      <th>origin_2</th>\n",
       "      <th>origin_3</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
       "\n",
       "   mpg_high  origin_1  origin_2  origin_3  const  \n",
       "0         0         1         0         0      1  \n",
       "1         0         1         0         0      1  \n",
       "2         0         1         0         0      1  \n",
       "3         0         1         0         0      1  \n",
       "4         0         1         0         0      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_log = pd.get_dummies(auto,columns=['origin'])\n",
    "auto_log = auto_log.drop(['name'], axis=1)\n",
    "\n",
    "auto_log['const']=1\n",
    "\n",
    "auto_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from pylab import rcParams\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "xvals = auto_log[['const','cylinders','displacement','horsepower',\n",
    "              'weight','acceleration','year','origin_1','origin_2']].values\n",
    "yvals = auto_log['mpg_high'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE Log Reg and K-fold= 0.09948979591836735\n",
      "Average Error Rate for mpg high = 1:  0.07794684205076571\n",
      "Average Error Rate for mpg high = 0:  0.1193288810332874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, random_state=25, shuffle=True)\n",
    "kf.get_n_splits(xvals)\n",
    "\n",
    "MSE_vec_kf = np.zeros(4)\n",
    "ones_error = np.zeros(4)\n",
    "zeros_error= np.zeros(4)\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(xvals):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    # print('k index=', k_ind)\n",
    "    X_train, X_test = xvals[train_index], xvals[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    LogReg = LogisticRegression(max_iter=300)\n",
    "    LogReg.fit(X_train, y_train)\n",
    "    y_pred = LogReg.predict(X_test)\n",
    "    MSE_vec_kf[k_ind] = ((y_test - y_pred) ** 2).mean()\n",
    "    ones_error[k_ind] = 1-((np.sum((y_test==1) & (y_pred==1)))/(np.sum(y_test==1)))\n",
    "    zeros_error[k_ind] = 1- ((np.sum((y_test==0) & (y_pred==0)))/(np.sum(y_test==0)))\n",
    "    # print('MSE for test set', k_ind, ' is', MSE_vec_kf[k_ind])\n",
    "    k_ind += 1\n",
    "\n",
    "MSE_logreg_kf = MSE_vec_kf.mean()\n",
    "print('Test MSE Log Reg and K-fold=', MSE_logreg_kf)\n",
    "print('Average Error Rate for mpg high = 1: ',ones_error.mean())\n",
    "print('Average Error Rate for mpg high = 0: ',zeros_error.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) \n",
    "Use sklearn.ensemble.RandomForestClassifier to fit a random forest model of mpg high on the eight possible features used in part (a). Use sklearn.model selection.RandomizedSearchCV to optimally tune the hyperparameters in the random forest classification model. Tune the pa- rameters n estimators, max depth, min samples split, min samples leaf, and max features. Set n iter=100, n jobs=-1, cv=4 for k = 4 k-fold cross validation, random state=25, and scoring=’neg mean squared error’. Set your Random Forest parameter distributions over which to test random combinations to the following:\n",
    "<br>\n",
    "param_dist3 = {’n_estimators’: [10, 200],\n",
    "<br>\n",
    "             ’max_depth’: [3, 8],\n",
    "              <br>\n",
    "             ’min_samples_split’: sp_randint(2, 20),\n",
    "             <br>\n",
    "             ’min_samples_leaf’: sp_randint(2, 20),\n",
    "             <br>\n",
    "             ’max_features’: sp_randint(1, 8)}\n",
    "<br>                         \n",
    "Report your optimal tuning parameter values (use the .best params object of your RandomizedSearchCV().fit(X, y)) results). Report the MSE of your optimal results (use the .best score object of your RandomizedSearchCV().fit(X, y)) results.\n",
    "\n",
    "#### Answer\n",
    "The optimal tuning parameters are: a max depth of 3, a minimum samples leaf of 17, a minimum samples split of 14, an n estimator of 10, and a maximum features of 7. <br>\n",
    "The test MSE for this model is 0.0553\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df = auto.drop(['name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvars= auto_df[['mpg','cylinders','displacement','horsepower','weight','acceleration','year','origin']]\n",
    "yvars= auto_df[['mpg_high']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xvars, yvars, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create first Random Forest object\n",
    "auto_rf = RandomForestClassifier()\n",
    "auto_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune hyperparameters\n",
    "param_rf = {'n_estimators': [10,200],\n",
    "                   'max_depth': [3, 8],'min_samples_split': sp_randint(2, 20),\n",
    "                   'min_samples_leaf': sp_randint(2, 20),'max_features':sp_randint(1,8)}\n",
    "\n",
    "auto_tune = RandomizedSearchCV(auto_rf, param_distributions=param_rf,\n",
    "                                    n_iter=100, n_jobs=-1, cv=4,\n",
    "                                   random_state=25,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TunedBestEstimator1= RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features=7, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=17, min_samples_split=14,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "TunedBestParams1= {'max_depth': 3, 'max_features': 7, 'min_samples_leaf': 17, 'min_samples_split': 14, 'n_estimators': 10}\n",
      "TunedBestScore1= -0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "auto_tune.fit(X_train,y_train)\n",
    "print('TunedBestEstimator1=', auto_tune.best_estimator_)\n",
    "print('TunedBestParams1=', auto_tune.best_params_)\n",
    "print('TunedBestScore1=', -auto_tune.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE 0.055321816810514776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:732: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    }
   ],
   "source": [
    "#Run new Random Forest with optimal parameters\n",
    "\n",
    "auto_rf_opt = RandomForestRegressor(n_estimators=10, max_depth=3, min_samples_split=14, min_samples_leaf=17,\n",
    "                                     max_features=7, bootstrap=True,\n",
    "                                     n_jobs=-1, oob_score=True, random_state=25)\n",
    "\n",
    "\n",
    "auto_rf_opt.fit(X_train,y_train)\n",
    "\n",
    "y_testpred_rf = auto_rf_opt.predict(X_test)\n",
    "MSE_randomforest = mean_squared_error(y_test, y_testpred_rf)\n",
    "print(\"Test MSE - Random Forest\",MSE_randomforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) \n",
    "Use sklearn.svm.SVC to fit a support vector machines model of mpg high\n",
    "with a Gaussian radial basis function kernel kernel=’rbf’ on the eight features used in parts (a) and (b). Use sklearn.model selection.RandomizedSearchCV to optimally tune the hyperparameters in the support vector machines classifier model. Tune the parameters C penalty parameter, gamma kernel coef-\n",
    "ficient, and shrinking. Set n iter=100, n jobs=-1, cv=4 for k = 4 k-fold cross validation, random state=25, and scoring=’neg mean squared error’. Set your SVM parameter distributions over which to test random combinations to the following:\n",
    "<br>\n",
    "param_dist4 = {’C’: sp_uniform(loc=0.2, scale=4.0),\n",
    "<br>\n",
    "             ’gamma’: [’scale’, ’auto’],\n",
    "             <br>\n",
    "             ’shrinking’: [True, False]}\n",
    "             <br>\n",
    "             \n",
    "Report your optimal tuning parameter values (use the .best params object of your RandomizedSearchCV().fit(X, y)) results). Report the MSE of your optimal results (use the .best score object of your RandomizedSearchCV().fit(X, y)) results.\n",
    "\n",
    "#### Answer\n",
    "The optimal tuning parameters are: a regularization parameter (C) of 1.8094, a gamma that is scaled, and not using shrinking. <br>\n",
    "The test MSE for this model is 0.0714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform as sp_uniform\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create first SVC object\n",
    "svc_auto = svm.SVC()\n",
    "svc_auto.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TunedBestEstimator1= SVC(C=1.8094629152568114, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=False,\n",
      "  tol=0.001, verbose=False)\n",
      "TunedBestParams1= {'C': 1.8094629152568114, 'gamma': 'scale', 'shrinking': False}\n",
      "TunedBestScore1= 0.09787234042553192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Tune hyperparameters\n",
    "param_svc = {'C': sp_uniform(loc=0.2, scale=4.0),\n",
    "             'gamma': ['scale', 'auto'],\n",
    "             'shrinking': [True, False]}\n",
    "\n",
    "svc_tune = RandomizedSearchCV(svc_auto, param_distributions=param_svc,\n",
    "                                    n_iter=100, n_jobs=-1, cv=4,\n",
    "                                   random_state=25,scoring='neg_mean_squared_error')\n",
    "\n",
    "svc_tune.fit(X_train,y_train)\n",
    "\n",
    "print('TunedBestEstimator1=', svc_tune.best_estimator_)\n",
    "print('TunedBestParams1=', svc_tune.best_params_)\n",
    "print('TunedBestScore1=', -svc_tune.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "#Run with optimal parameters\n",
    "\n",
    "svc_opt = svc_auto = svm.SVC(kernel='rbf', gamma='scale', C=3.23683,shrinking=False)\n",
    "svc_opt.fit(X_train,y_train)\n",
    "\n",
    "y_testpred_sv = svc_opt.predict(X_test)\n",
    "MSE_svm = mean_squared_error(y_test, y_testpred_sv)\n",
    "print(\"Test MSE\",MSE_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) \n",
    "Which of the above three models do you think is the best predictor of mpg high? Why?\n",
    "\n",
    "#### Answer\n",
    "The random forest from part b has the lowest Test MSE, so there's good reason to believe that model would best predict mpg high given the features from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression (a)</th>\n",
       "      <th>Random Forest (b)</th>\n",
       "      <th>Support Vector Machines (c)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.09949</td>\n",
       "      <td>0.055322</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Logistic Regression (a)  Random Forest (b)  Support Vector Machines (c)\n",
       "MSE                  0.09949           0.055322                     0.071429"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Logistic Regression (a)':MSE_logreg_kf,\n",
    "                        'Random Forest (b)':MSE_randomforest,\n",
    "                        'Support Vector Machines (c)':MSE_svm},\n",
    "                       index=['MSE'])\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
